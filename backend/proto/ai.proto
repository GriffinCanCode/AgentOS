syntax = "proto3";

package ai;

option go_package = "github.com/GriffinCanCode/AgentOS/backend/proto/ai";

// AI service for LLM operations
service AIService {
  // Generate UI specification from natural language
  rpc GenerateUI(UIRequest) returns (UIResponse);

  // Stream chat response with thoughts
  rpc StreamChat(ChatRequest) returns (stream ChatToken);

  // Stream UI generation with real-time updates
  rpc StreamUI(UIRequest) returns (stream UIToken);
}

message UIRequest {
  string message = 1;
  map<string, string> context = 2;
  optional string parent_id = 3;  // ULID format: app_01ARZ3NDEKTSV4RRFFQ69G5FAV
}

message UIResponse {
  string app_id = 1;           // ULID format: app_01ARZ3NDEKTSV4RRFFQ69G5FAV
  string ui_spec_json = 2;
  repeated string thoughts = 3;
  bool success = 4;
  optional string error = 5;
}

message ChatRequest {
  string message = 1;
  map<string, string> context = 2;
  repeated ChatMessage history = 3;
}

message ChatMessage {
  string role = 1;
  string content = 2;
  int64 timestamp = 3;
}

message ChatToken {
  enum Type {
    GENERATION_START = 0;
    TOKEN = 1;
    THOUGHT = 2;
    COMPLETE = 3;
    ERROR = 4;
  }

  Type type = 1;
  string content = 2;
  int64 timestamp = 3;
}

message UIToken {
  enum Type {
    GENERATION_START = 0;
    THOUGHT = 1;
    TOKEN = 2;
    COMPLETE = 3;
    ERROR = 4;
  }

  Type type = 1;
  string content = 2;
  int64 timestamp = 3;
}


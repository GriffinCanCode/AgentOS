# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: ai.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder

_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC, 5, 29, 0, "", "ai.proto"
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
    b'\n\x08\x61i.proto\x12\x02\x61i"\x9f\x01\n\tUIRequest\x12\x0f\n\x07message\x18\x01 \x01(\t\x12+\n\x07\x63ontext\x18\x02 \x03(\x0b\x32\x1a.ai.UIRequest.ContextEntry\x12\x16\n\tparent_id\x18\x03 \x01(\tH\x00\x88\x01\x01\x1a.\n\x0c\x43ontextEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x42\x0c\n\n_parent_id"s\n\nUIResponse\x12\x0e\n\x06\x61pp_id\x18\x01 \x01(\t\x12\x14\n\x0cui_spec_json\x18\x02 \x01(\t\x12\x10\n\x08thoughts\x18\x03 \x03(\t\x12\x0f\n\x07success\x18\x04 \x01(\x08\x12\x12\n\x05\x65rror\x18\x05 \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_error"\x9f\x01\n\x0b\x43hatRequest\x12\x0f\n\x07message\x18\x01 \x01(\t\x12-\n\x07\x63ontext\x18\x02 \x03(\x0b\x32\x1c.ai.ChatRequest.ContextEntry\x12 \n\x07history\x18\x03 \x03(\x0b\x32\x0f.ai.ChatMessage\x1a.\n\x0c\x43ontextEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"?\n\x0b\x43hatMessage\x12\x0c\n\x04role\x18\x01 \x01(\t\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\x12\x11\n\ttimestamp\x18\x03 \x01(\x03"\xa0\x01\n\tChatToken\x12 \n\x04type\x18\x01 \x01(\x0e\x32\x12.ai.ChatToken.Type\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\x12\x11\n\ttimestamp\x18\x03 \x01(\x03"M\n\x04Type\x12\x14\n\x10GENERATION_START\x10\x00\x12\t\n\x05TOKEN\x10\x01\x12\x0b\n\x07THOUGHT\x10\x02\x12\x0c\n\x08\x43OMPLETE\x10\x03\x12\t\n\x05\x45RROR\x10\x04"\x9c\x01\n\x07UIToken\x12\x1e\n\x04type\x18\x01 \x01(\x0e\x32\x10.ai.UIToken.Type\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\x12\x11\n\ttimestamp\x18\x03 \x01(\x03"M\n\x04Type\x12\x14\n\x10GENERATION_START\x10\x00\x12\x0b\n\x07THOUGHT\x10\x01\x12\t\n\x05TOKEN\x10\x02\x12\x0c\n\x08\x43OMPLETE\x10\x03\x12\t\n\x05\x45RROR\x10\x04\x32\x92\x01\n\tAIService\x12+\n\nGenerateUI\x12\r.ai.UIRequest\x1a\x0e.ai.UIResponse\x12.\n\nStreamChat\x12\x0f.ai.ChatRequest\x1a\r.ai.ChatToken0\x01\x12(\n\x08StreamUI\x12\r.ai.UIRequest\x1a\x0b.ai.UIToken0\x01\x62\x06proto3'
)

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, "ai_pb2", _globals)
if not _descriptor._USE_C_DESCRIPTORS:
    DESCRIPTOR._loaded_options = None
    _globals["_UIREQUEST_CONTEXTENTRY"]._loaded_options = None
    _globals["_UIREQUEST_CONTEXTENTRY"]._serialized_options = b"8\001"
    _globals["_CHATREQUEST_CONTEXTENTRY"]._loaded_options = None
    _globals["_CHATREQUEST_CONTEXTENTRY"]._serialized_options = b"8\001"
    _globals["_UIREQUEST"]._serialized_start = 17
    _globals["_UIREQUEST"]._serialized_end = 176
    _globals["_UIREQUEST_CONTEXTENTRY"]._serialized_start = 116
    _globals["_UIREQUEST_CONTEXTENTRY"]._serialized_end = 162
    _globals["_UIRESPONSE"]._serialized_start = 178
    _globals["_UIRESPONSE"]._serialized_end = 293
    _globals["_CHATREQUEST"]._serialized_start = 296
    _globals["_CHATREQUEST"]._serialized_end = 455
    _globals["_CHATREQUEST_CONTEXTENTRY"]._serialized_start = 116
    _globals["_CHATREQUEST_CONTEXTENTRY"]._serialized_end = 162
    _globals["_CHATMESSAGE"]._serialized_start = 457
    _globals["_CHATMESSAGE"]._serialized_end = 520
    _globals["_CHATTOKEN"]._serialized_start = 523
    _globals["_CHATTOKEN"]._serialized_end = 683
    _globals["_CHATTOKEN_TYPE"]._serialized_start = 606
    _globals["_CHATTOKEN_TYPE"]._serialized_end = 683
    _globals["_UITOKEN"]._serialized_start = 686
    _globals["_UITOKEN"]._serialized_end = 842
    _globals["_UITOKEN_TYPE"]._serialized_start = 765
    _globals["_UITOKEN_TYPE"]._serialized_end = 842
    _globals["_AISERVICE"]._serialized_start = 845
    _globals["_AISERVICE"]._serialized_end = 991
# @@protoc_insertion_point(module_scope)
